\section{Iteration 3: Decomposition of the Storage Scheduler}
\label{add:it3}

\subsection{Step 1: Identify candidate drivers}
\label{add:it3/drivers}

\npar Trame processing is the core business of the ReMeS system. Almost all
components in the ReMeS system need access to the trames database.
However, not all queries on that database should be treated equally. For
instance, research queries have a lower priority than anomaly detection history
queries (see P3). Therefore, queries to the measurements database need to be
scheduled.

\npar The decomposition of this iteration is driven by

\begin{itemize}
  	\item Av1: Measurements database failure. In case the database goes down, at
  	least 3 hours of measurement data should be stored.
	\item P1': Timely closure of valves. Alarm trames should be processed with a
	higher priority because valves have to be shut within a bounded time in case of
	an alarm.
	\item P2': Anomaly detection: Anomaly detection will be triggered for every
	incoming measurement trame. Measurement trames will also have a higher
	priority because incoming trames should be fully processed within a bounded
	time.
	\item P3': Requests to the measurements database: These queries are subjected
	to a maximal execution time based on the SLA. 
\end{itemize}

% TODO: use cases nog oplijsten

\subsection{Step 2: Choose design concepts}
\label{add:it3/concepts}

\subsubsection{Tactics}
\label{add:it3/tactics}

\npar The scheduler was introduced in iteration 1 (see section \ref{add:it1}) to
improve performance. At the level of the scheduler, performance is determined by
the scheduling policy. 

\npar The scheduling policy is defined by the quality attributes but the
scheduler itself can be implemented in different ways. One could use a single
queue for the scheduler. Jobs are pushed on the queue and popped off when the
scheduler can process a new job. 

\npar A scheduler can also be implemented with multiple queues. For each kind of
job, there is a seperate queue. In this case, you would end up with a number of
queues for different priorities. Whenever a job resides in a queue for a long
time, it is promoted to a higher priority queue. 

\npar A scheduler must also guarantee that there will be no starvation among
jobs. Starvation happens when a job cannot execute because there always is a
job with a higher priority. When using a first in, first out policy, starvation
will not occur. However, when the database goes into overload mode, this might
become an issue. 

\npar To address this issue, a dynamic priority scheme will be used. The
priority of every job will be increased periodically. In this way, low priority
jobs will eventually have a high priority. 

\subsubsection{Design Patterns}
\label{add:it3/patterns}

\paragraph{Collections for States}

\npar The collections for states design pattern describes a way to efficiently
implement a scheduler with multiple queues. In a client, every state is
represented by a collection of objects with that state. The collections for
each state would be implemented with queues and the the states would represent
priority levels.

\paragraph{Strategy}

\npar If the scheduler allows for multiple policies, the strategy design pattern
can be used to implement these policies. The behaviour of the message router
will be determined by the policy.

\paragraph{Monitor} 

\npar Because the queues can be accessed by both the scheduler and the message
router, monitors have to be put in place to provide synchronization. This is
done to make sure that there aren't any concurrency issues within the scheduler. 

\paragraph{PriorityQueue}

\npar This is not a design pattern but a data type. This queue allows elements
to be inserted with a given priority. This could simplify the design by merging
all queues into one big queue.

\npar There is not really an advantage in having multiple queues. There is only
one instance that can process the jobs. The overhead of comparing the top
entries of the queues might also be large, making this solution less efficient. 

\subsection{Step 3: Instantiate architectural elements and allocate responsibilities}
\label{add:it3/elements}

\npar All requests to the Trame Storage are encapsulated as Query Objects. These
objects are created in the Remote Module Communication Unit and are presented to
the Trame Scheduler. A Callback is stored in the Query objects to return the
result to the issuer. 

\npar When presented, these Queries are temporarily stored in a Buffer, called
TrameSchedulingBuffer. This buffer is capable of holding up to 3 hours of
measurements data in case of a problem with scheduling or the database. 

\npar A Scheduler will pop Queries of the buffer and store them in a
PriorityQueue, called TrameSchedulingQueue. The Queries will be inserted with a
certain priority, determined by a policy that is based on the load, types of
trames, etc.

\npar A QueueReader will pop of the Query with the highest priority and execute
it on the database. 

\npar In case the database becomes unavailable and the Scheduler can no longer
schedule queries because the queue is full, the queries are collected in the
buffer.

\subsection{Step 4: Define interfaces for instantiated elements}
\label{add:it3/interfaces}

%
% --schedule(Query):void--> [Buffer] <--pop():Query--[Scheduler]
%                                                         |
%                                        schedule(Query,PriorityQueue):void
%                                                         |
%                                                         v
%               [PriorityQueue]<--enqueue(Query):void--[Policy]
%                      ^
%                      |
%                pop() : Query
%                      |
%                [QueueReader]--execute(Query):Result-->[[TrameStorage]]


\subsubsection{TrameSchedulingBuffer}

\npar The TrameSchedulingBuffer exposes an interface
\interface{TrameSchedulingAPI} to the Communication Unit. This interface
contains a method \method{schedule(Query) : void} and is used to add a Query to
the Buffer.

\npar This component also provides an interface to the Scheduler. The Scheduler
will invoke the method \method{pop() : Query} to pop a Query off the top of the
buffer.

\subsubsection{Policy}

\npar The Query will then be inserted in the PriorityQueue (scheduled) by
invoking the \method{schedule(Query, PriorityQueue) : void} on the current
Policy. 



\subsubsection{Queue}

\npar The Queue provides an interface \interface{StorageSchedulerQueue} with the
methods \method{enqueue(Query, priority)} and \method{dequeue() : Query}. These
methods are used to enqueue and repectively dequeue queries.

\subsubsection{Scheduler}

\npar The Scheduler itself does not provide an interface, but uses the
\interface{Queue} to dequeue items and uses the interface of the trame storage
database to execute the queries.

\npar Figure \ref{fig:it3/interfaces} shows the components and the interfaces
instantiated in this iteration.

\begin{figure}[H]
	\begin{centering}
		%\includegraphics[width=0.8\textwidth]{figs/add/it3/interfaces.pdf}
		\caption{Overview of the interfaces and components of the storage scheduler.}
		\label{fig:it3/interfaces}
	\end{centering}
\end{figure}

\subsection{Step 5: Verify and refine}
\label{add:it3/verification}

\npar All quality and functionality is handled in this decomposition.  

\begin{itemize}
	\item P1': Timely propagation of alarm trames is handled by smart Queue
	insertion by the Message Router. 
	\item P2': Timely propagation of measurement trames is also handled by smart
	Queue insertion by the Message Router. 
	\item P3': Potential prioritization of certain database queries. 
\end{itemize}
